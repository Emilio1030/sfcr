{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57226901",
   "metadata": {},
   "source": [
    "# Converting the PDF files into vector database  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f7c8d88",
   "metadata": {},
   "source": [
    "# 1. Initial setup\n",
    "## 1.1. Imports\n",
    "This setup includes loading environment variables from a `.env` file, setting the required environment variables, and importing the necessary modules for further processing. It ensures that the code has access to the required APIs and functions for the subsequent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1440f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fc759e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHUGGINGFACE_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#openai.api_key = os.getenv('OPENAI_API_KEY')\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Langchain framework\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the variables from .env file and set the API key (or user may manually set the API key)\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv('ANTHROPIC_API_KEY')\n",
    "os.environ[\"MATHPIX_API_ID\"] = os.getenv('MATHPIX_API_KEY')\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv('HUGGINGFACE_API_KEY')\n",
    "#openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Langchain framework\n",
    "from langchain import hub\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel # for RAG with source\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "## The following loaders are used for options\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_community.document_loaders import MathpixPDFLoader\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84652248",
   "metadata": {},
   "source": [
    "## 1.2. Initial variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35630ca8-a707-4445-b8a2-661fe3312d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial variable setup\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "db_directory = \"../data/chroma_semantic\"\n",
    "USE_Anthropic = True\n",
    "\n",
    "if USE_Anthropic:\n",
    "    llm = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\", temperature=0)\n",
    "\n",
    "else:\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # context window size 16k for GPT 3.5 Turbo\n",
    "\n",
    "\n",
    "collection_list=[\n",
    "    #\"legislation\",\n",
    "    \"ifrs17\"\n",
    "    \"solvencia_2\",\n",
    "    \"reg_delegado\",\n",
    "    \"reg_execucao\"\n",
    "]\n",
    "#collection_list = [\"PBR\"] # for testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04673e4",
   "metadata": {},
   "source": [
    "# 2. Load PDF files and convert to a vector DB\n",
    "## 2.1. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and extract text from PDFs in a folder\n",
    "def get_file_name(source_path):\n",
    "    return source_path.split('/')[-1]\n",
    "\n",
    "def load_pdfs_from_folder(folder_path, loader_option):\n",
    "    # Get a list of PDF files in the specified folder\n",
    "    pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        file_name = get_file_name(pdf_file)\n",
    "\n",
    "        if loader_option == 1:\n",
    "            # Load the PDF file using the PyPDFLoader\n",
    "            loader = PyPDFLoader(pdf_file)\n",
    "        elif loader_option == 2:\n",
    "            # PyPDFium2Loader is known to be faster than PyPDFLoader\n",
    "            loader = PyPDFium2Loader(pdf_file)\n",
    "        elif loader_option == 3:\n",
    "            # PyMuPDFLoader is known to be general purpose, rich metadata\n",
    "            loader = PyMuPDFLoader(pdf_file)\n",
    "        elif loader_option == 4:\n",
    "            # Allows automated concatenate pages\n",
    "            loader = PDFMinerLoader(pdf_file, concatenate_pages=True)\n",
    "\n",
    "        loaded_docs = loader.load()\n",
    "\n",
    "        for doc in loaded_docs:\n",
    "            doc.metadata['source'] = file_name\n",
    "\n",
    "        docs.extend(loaded_docs)\n",
    "    return docs\n",
    "\n",
    "def pdf_to_md(folder_path, download_path, loader_option):\n",
    "    # Get a list of PDF files in the specified folder\n",
    "    pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    for pdf_file in pdf_files:\n",
    "        file_name = get_file_name(pdf_file)\n",
    "        base_name = file_name.replace('.pdf', '')\n",
    "\n",
    "        if loader_option == 1:\n",
    "            # Load the PDF file using the PyPDFLoader\n",
    "            loader = PyPDFLoader(pdf_file)\n",
    "        elif loader_option == 2:\n",
    "            # PyPDFium2Loader is known to be faster than PyPDFLoader\n",
    "            loader = PyPDFium2Loader(pdf_file)\n",
    "        elif loader_option == 3:\n",
    "            # PyMuPDFLoader is known to be general purpose, rich metadata\n",
    "            loader = PyMuPDFLoader(pdf_file)\n",
    "        elif loader_option == 4:\n",
    "            # Allows automated concatenate pages\n",
    "            loader = PDFMinerLoader(pdf_file, concatenate_pages=True)\n",
    "        elif loader_option == 5:\n",
    "            # Use Mathpix OCR to load formula, tables\n",
    "            # may be slower, but higher quality than all above\n",
    "            # Require Mathpix API ID - 3 cents per pdf page\n",
    "            loader = MathpixPDFLoader(pdf_file)\n",
    "\n",
    "        loaded_docs = loader.load()\n",
    "\n",
    "        for i, doc in enumerate(loaded_docs):\n",
    "            doc.metadata['source'] = file_name\n",
    "            if loader_option > 3:\n",
    "                md_file_name = f\"{download_path}/{base_name}.md\"\n",
    "            else:\n",
    "                md_file_name = f\"{download_path}/{base_name}{i+1:03d}.md\"\n",
    "            with open(md_file_name, 'w', encoding='utf-8') as md_file:\n",
    "                md_file.write(doc.page_content)\n",
    "\n",
    "def load_mds_from_folder(folder_path):\n",
    "    # Get a list of md files in the specified folder\n",
    "    md_files = glob.glob(f\"{folder_path}/*.md\")\n",
    "    docs = []\n",
    "    for md_file in md_files:\n",
    "        file_name = get_file_name(md_file)\n",
    "        base_name = file_name.replace('.md', '')\n",
    "        pdf_file_name = f\"{base_name}.pdf\"\n",
    "\n",
    "        loader = UnstructuredMarkdownLoader(md_file)\n",
    "        loaded_docs = loader.load()\n",
    "        #print(loaded_docs)\n",
    "        for doc in loaded_docs:\n",
    "            doc.metadata['source'] = pdf_file_name\n",
    "            print(pdf_file_name)\n",
    "        docs.extend(loaded_docs)\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7ad53a",
   "metadata": {},
   "source": [
    "## 2.2. Convert PDFs to markdown files and then convert to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb282c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Run only to convert pdf to markdown files\n",
    "############################################################################\n",
    "\n",
    "collection_list=[\n",
    "    #\"legislation\",\n",
    "    #\"ifrs17\",\n",
    "    #\"solvencia_2\",\n",
    "    \"reg_delegado\",\n",
    "    #\"reg_execucao\"\n",
    "]\n",
    "for collection_name in collection_list:\n",
    "    # Put new files in the upload subfolder\n",
    "    folder_path = '../data/pdf/'+collection_name\n",
    "    download_path = '../data/md/'+collection_name\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "    # Use loader option 5 to use Mathpix OCR to load formula, tables\n",
    "    pdf_to_md(folder_path, download_path, loader_option = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELEX_32015R0035_PT_TXT.pdf\n",
      "CELEX_32015R0035_EN_TXT.pdf\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "# Run to load markdown files to vector database\n",
    "############################################################################\n",
    "collection_list=[\n",
    "    #\"legislation\",\n",
    "    #\"ifrs17\",\n",
    "    #\"solvencia_2\",\n",
    "    \"reg_delegado_v2\", # i have doubt in this one\n",
    "    #\"reg_execucao\"\n",
    "]\n",
    "\n",
    "for collection_name in collection_list:\n",
    "    # Put new files in the upload subfolder\n",
    "    folder_path = '../data/md/'+collection_name\n",
    "\n",
    "    # Call the function to load and extract text from PDFs in the specified folder\n",
    "    docs = load_mds_from_folder(folder_path)\n",
    "\n",
    "    #Create a text splitter object with specified parameters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, # 1000 splits a page into roughly 3 chunks\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,)\n",
    "\n",
    "    # Use semantic chunker to increase meaningfulness of the chunks\n",
    "    #text_splitter = SemanticChunker(embeddings_model, number_of_chunks = 1000)\n",
    "\n",
    "    # Split the documents into chunks using the text splitter\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Create a Chroma vector database from the document splits\n",
    "    Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings_model,\n",
    "        persist_directory=db_directory,\n",
    "        collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i can try different embeddings and see the results based on the questions i ask\n",
    "# source\n",
    "## embeddings\n",
    "### https://huggingface.co/spaces/mteb/leaderboard\n",
    "## models\n",
    "### https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a41b27f5",
   "metadata": {},
   "source": [
    "## 2.3. (NOT USED) Convert PDFs to vector database directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Run to load pdf files to vector database\n",
    "############################################################################\n",
    "\n",
    "for collection_name in collection_list:\n",
    "    # Put new files in the upload subfolder\n",
    "    folder_path = './data/upload/pdf/'+collection_name\n",
    "\n",
    "    # Call the function to load and extract text from PDFs in the specified folder\n",
    "    docs = load_pdfs_from_folder(folder_path, loader_option = 1)\n",
    "\n",
    "    # Create a text splitter object with specified parameters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "         chunk_size=1000, # 1000 splits a page into roughly 3 chunks\n",
    "         chunk_overlap=200,\n",
    "         length_function=len,)\n",
    "\n",
    "    # Use semantic chunker to increase meaningfulness of the chunks\n",
    "    text_splitter = SemanticChunker(embeddings_model)\n",
    "\n",
    "    # Split the documents into chunks using the text splitter\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Create a Chroma vector database from the document splits\n",
    "    Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings_model,\n",
    "        persist_directory=db_directory,\n",
    "        collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d46105ba",
   "metadata": {},
   "source": [
    "# 3. For test purposes\n",
    "## 3.1. Define vector store from vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab19628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ifrs17solvencia_2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9abd0f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "file is not a database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m collection_list[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get a Chroma vector database with specified parameters\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_community/vectorstores/chroma.py:120\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    118\u001b[0m         _client_settings \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSettings()\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m _client_settings\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_client_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persist_directory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m         _client_settings\u001b[38;5;241m.\u001b[39mpersist_directory \u001b[38;5;129;01mor\u001b[39;00m persist_directory\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;241m=\u001b[39m embedding_function\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/__init__.py:274\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings, tenant, database)\u001b[0m\n\u001b[1;32m    271\u001b[0m tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[1;32m    272\u001b[0m database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/api/client.py:139\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, tenant, database, settings)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    135\u001b[0m     tenant: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_TENANT,\n\u001b[1;32m    136\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    137\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m    138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant \u001b[38;5;241m=\u001b[39m tenant\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase \u001b[38;5;241m=\u001b[39m database\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/api/client.py:43\u001b[0m, in \u001b[0;36mSharedSystemClient.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     40\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m     41\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m SharedSystemClient\u001b[38;5;241m.\u001b[39m_get_identifier_from_settings(settings)\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mSharedSystemClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/api/client.py:56\u001b[0m, in \u001b[0;36mSharedSystemClient._create_system_if_not_exists\u001b[0;34m(cls, identifier, settings)\u001b[0m\n\u001b[1;32m     53\u001b[0m     new_system\u001b[38;5;241m.\u001b[39minstance(ProductTelemetryClient)\n\u001b[1;32m     54\u001b[0m     new_system\u001b[38;5;241m.\u001b[39minstance(ServerAPI)\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mnew_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     previous_system \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_identifer_to_system[identifier]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/config.py:403\u001b[0m, in \u001b[0;36mSystem.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents():\n\u001b[0;32m--> 403\u001b[0m     \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/db/impl/sqlite.py:100\u001b[0m, in \u001b[0;36mSqliteDB.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRAGMA foreign_keys = ON\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRAGMA case_sensitive_like = ON\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_migrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/db/migrations.py:140\u001b[0m, in \u001b[0;36mMigratableDB.initialize_migrations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_migrations()\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m migrate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_migrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/db/migrations.py:165\u001b[0m, in \u001b[0;36mMigratableDB.apply_migrations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMigratableDB.apply_migrations\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mALL)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_migrations\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate existing migrations, and apply all new ones.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_migrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmigration_dirs():\n\u001b[1;32m    167\u001b[0m         db_migrations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_migrations(\u001b[38;5;28mdir\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/chromadb/db/impl/sqlite.py:158\u001b[0m, in \u001b[0;36mSqliteDB.setup_migrations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSqliteDB.setup_migrations\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mALL)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_migrations\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[0;32m--> 158\u001b[0m         \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250;43m            \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;43;03m                CREATE TABLE IF NOT EXISTS migrations (\u001b[39;49;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;43;03m                    dir TEXT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;43;03m                    version INTEGER NOT NULL,\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;43;03m                    filename TEXT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;43;03m                    sql TEXT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;43;03m                    hash TEXT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;43;03m                    PRIMARY KEY (dir, version)\u001b[39;49;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;43;03m                )\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;43;03m                \"\"\"\u001b[39;49;00m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: file is not a database"
     ]
    }
   ],
   "source": [
    "## a user may choose different collection name from the list\n",
    "# [\"ASOP_life\", \"Bermuda\", \"CFT\", \"VM21\", \"VM22\", \"Asset\", \"IFRS17\"]\n",
    "collection_name = 'ifrs17' collection_list[0]\n",
    "\n",
    "# Get a Chroma vector database with specified parameters\n",
    "vectorstore = Chroma(embedding_function=embeddings_model,\n",
    "                     persist_directory=db_directory,\n",
    "                     collection_name=collection_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90a4d0e8",
   "metadata": {},
   "source": [
    "## 3.2. Retrieve from the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve and RAG chain\n",
    "# Create a retriever using the vector database as the search source\n",
    "# You may choose a specific document to filter the search\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\",\n",
    "                                     search_kwargs={\n",
    "                                        'k': 6,\n",
    "                                        'lambda_mult': 0.5,\n",
    "                                        # 'filter': {'source': '201611-Guidance-Notes-for-Commercial-Insurers-and-Groups-Statutory-Reporting-Regime-30-Nov-2016.pdf'}\n",
    "                                        }\n",
    "                                    )\n",
    "# Use MMR (Maximum Marginal Relevance) to find a set of documents that are both similar to the input query and diverse among themselves\n",
    "# Increase the number of documents to get, and increase diversity (lambda mult 0.5 being default, 0 being the most diverse, 1 being the least)\n",
    "\n",
    "# Load the RAG (Retrieval-Augmented Generation) prompt\n",
    "qa_system_prompt = \"\"\"You are a helpful assistant to help actuaries with question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "IFRS17 it means International Financial Reporting Standard. \\\n",
    "CFT means Cash Flow Testing. AAT means Asset Adequacy Testing. \\\n",
    "ASF means Autoridade de Supervisão de Seguros e Fundos de Pensões. \\\n",
    "BEL means best estimate liabilities.\\\n",
    "After you answer, provide the sources you used to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "\n",
    "{context}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define a function to format the documents with their sources and pages\n",
    "def format_docs_with_sources(docs):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    #sources_pages = \"\\n\".join(f\"{doc.metadata['source']} (Page {doc.metadata['page'] + 1})\" for doc in docs)\n",
    "    sources_pages = \"\\n\".join(f\"{doc.metadata['source']})\" for doc in docs)\n",
    "    # Added 1 to the page number assuming 'page' starts at 0 and we want to present it in a user-friendly way\n",
    "\n",
    "    return f\"Documents:\\n{formatted_docs}\\n\\nSources and Pages:\\n{sources_pages}\"\n",
    "\n",
    "# Create a RAG chain using the formatted documents as the context\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs_with_sources(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create a parallel chain for retrieving and generating answers\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9243e34a",
   "metadata": {},
   "source": [
    "## 3.3. Generate Q&A Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceedb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output():\n",
    "    # Prompt the user for a question on ASOP\n",
    "    usr_input = input(\"What is your question on Solvency II?: \")\n",
    "\n",
    "    # Invoke the RAG chain with the user input as the question\n",
    "    output = rag_chain_with_source.invoke(usr_input)\n",
    "\n",
    "    # Generate the Markdown output with the question, answer, and context\n",
    "    markdown_output = \"### Question\\n{}\\n\\n### Answer\\n{}\\n\\n### Context\\n\".format(output['question'], output['answer'])\n",
    "\n",
    "    last_page_content = None  # Variable to store the last page content\n",
    "    i = 1 # Source indicator\n",
    "\n",
    "    # Iterate over the context documents to format and include them in the output\n",
    "    for doc in output['context']:\n",
    "        current_page_content = doc.page_content.replace('\\n', '  \\n')  # Get the current page content\n",
    "\n",
    "        # Check if the current content is different from the last one\n",
    "        if current_page_content != last_page_content:\n",
    "            #markdown_output += \"- **Source {}**: {}, page {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], doc.metadata['page'], current_page_content)\n",
    "            markdown_output += \"- **Source {}**: {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], current_page_content)\n",
    "            i = i + 1\n",
    "        last_page_content = current_page_content  # Update the last page content\n",
    "\n",
    "    # Display the Markdown output\n",
    "    display(Markdown(markdown_output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d54daa6",
   "metadata": {},
   "source": [
    "### Example questions related to ASOPs\n",
    "- explain ASOP No. 14\n",
    "- How are expenses relfected in cash flow testing based on ASOP No. 22?\n",
    "- What is catastrophe risk?\n",
    "- When do I update assumptions?\n",
    "- What should I do when I do not have credible data to develop non-economic assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36183436",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 405 Client Error: Method Not Allowed for url: https://ui.endpoints.huggingface.co/Emilio1030/new?repository=davidkim205%2FRhea-72b-v0.5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_output()\n",
      "Cell \u001b[0;32mIn[84], line 6\u001b[0m, in \u001b[0;36mgenerate_output\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m usr_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWhat is your question on Solvency II?: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Invoke the RAG chain with the user input as the question\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m output \u001b[39m=\u001b[39m rag_chain_with_source\u001b[39m.\u001b[39;49minvoke(usr_input)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Generate the Markdown output with the question, answer, and context\u001b[39;00m\n\u001b[1;32m      9\u001b[0m markdown_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m### Question\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m### Answer\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m### Context\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(output[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m], output[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2500\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2501\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m             patch_config(\n\u001b[1;32m   2503\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2504\u001b[0m             ),\n\u001b[1;32m   2505\u001b[0m         )\n\u001b[1;32m   2506\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/passthrough.py:453\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    448\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    449\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    450\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    451\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    452\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 453\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke, \u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1622\u001b[0m     context\u001b[39m.\u001b[39mrun(var_child_runnable_config\u001b[39m.\u001b[39mset, child_config)\n\u001b[1;32m   1623\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1624\u001b[0m         Output,\n\u001b[0;32m-> 1625\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1626\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1627\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m             config,\n\u001b[1;32m   1630\u001b[0m             run_manager,\n\u001b[1;32m   1631\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1632\u001b[0m         ),\n\u001b[1;32m   1633\u001b[0m     )\n\u001b[1;32m   1634\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1635\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/passthrough.py:440\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[1;32m    428\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    429\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    433\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    434\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    435\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mdict\u001b[39m\n\u001b[1;32m    436\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    439\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m--> 440\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapper\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    441\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    442\u001b[0m             patch_config(config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child()),\n\u001b[1;32m    443\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    444\u001b[0m         ),\n\u001b[1;32m    445\u001b[0m     }\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2500\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2501\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m             patch_config(\n\u001b[1;32m   2503\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2504\u001b[0m             ),\n\u001b[1;32m   2505\u001b[0m         )\n\u001b[1;32m   2506\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    277\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    278\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    279\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    280\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    282\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    283\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    284\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    285\u001b[0m         )\n\u001b[1;32m    286\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    804\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    805\u001b[0m     )\n\u001b[1;32m    806\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    658\u001b[0m                 prompts,\n\u001b[1;32m    659\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    663\u001b[0m             )\n\u001b[1;32m    664\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1318\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/langchain_community/llms/huggingface_endpoint.py:256\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     invocation_params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m invocation_params[\n\u001b[1;32m    254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m     ]  \u001b[39m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    257\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: invocation_params},\n\u001b[1;32m    258\u001b[0m         stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m         task\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask,\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     response_text \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mdecode())[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    263\u001b[0m     \u001b[39m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/huggingface_hub/inference/_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[39mraise\u001b[39;00m InferenceTimeoutError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInference call timed out: \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror\u001b[39;00m  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     hf_raise_for_status(response)\n\u001b[1;32m    274\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39miter_lines() \u001b[39mif\u001b[39;00m stream \u001b[39melse\u001b[39;00m response\u001b[39m.\u001b[39mcontent\n\u001b[1;32m    275\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[39mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[39m=\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[39mraise\u001b[39;00m HfHubHTTPError(\u001b[39mstr\u001b[39;49m(e), response\u001b[39m=\u001b[39;49mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/akaquery/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:88\u001b[0m, in \u001b[0;36mHfHubHTTPError.__init__\u001b[0;34m(self, message, response)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(server_message_from_body, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     87\u001b[0m         server_message_from_body \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(server_message_from_body)\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mif\u001b[39;00m server_message_from_body \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m _server_message:\n\u001b[1;32m     89\u001b[0m         _server_message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m server_message_from_body \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m server_multiple_messages_from_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# from body \"errors\"\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not dict"
     ]
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5938771",
   "metadata": {},
   "source": [
    "# 4. References\n",
    "- https://www.actuarialstandardsboard.org/standards-of-practice/\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/quickstart\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/sources\n",
    "- https://python.langchain.com/docs/integrations/text_embedding/\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "- https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All\n",
    "- https://chat.langchain.com/\n",
    "- https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "628913a4",
   "metadata": {},
   "source": [
    "# 5. Management of the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=db_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e514b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_collection(name=\"VM20\") # Delete a collection and all associated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(name=\"AI_BigData\")\n",
    "collection.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5025ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection.modify(name=\"PBR\") rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Get all the metadatas\n",
    "metadatas = collection.get()['metadatas']\n",
    "\n",
    "# Create a dictionary to store distinct source names\n",
    "distinct_sources = defaultdict(set)\n",
    "\n",
    "# Iterate through metadatas and add source names to the dictionary\n",
    "for metadata in metadatas:\n",
    "    source = metadata.get('source', None)\n",
    "    if source:\n",
    "        distinct_sources[source].add(source)\n",
    "\n",
    "# Get the distinct source names as a list\n",
    "distinct_source_names = list(distinct_sources.keys())\n",
    "\n",
    "print(distinct_source_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.get(\n",
    "    where={\"source\": \"2023_BMA-Supervision-and-Regulation-of-Private-Equity-Insurers.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete(\n",
    "    #ids=[\"id1\", \"id2\", \"id3\",...],\n",
    "    where={\"source\": \"VA_PN_Supplement_Exposure_Draft.pdf\"}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f66a6a9c",
   "metadata": {},
   "source": [
    "# Rename process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1410cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename process\n",
    "folder_name = \"VM22\"\n",
    "old_file_name = \"VM-22 Subgroup Draft July 2023 Clean.pdf\"\n",
    "new_file_name = \"202307-NAIC-VM-22 Subgroup Draft.pdf\"\n",
    "\n",
    "# Chroma DB update\n",
    "collection = client.get_collection(name=folder_name)\n",
    "results = collection.get(where={\"source\": old_file_name})\n",
    "ids_to_update = results['ids']\n",
    "print(ids_to_update)\n",
    "new_metadatas = [{\"source\": new_file_name} for _ in ids_to_update]\n",
    "collection.update(ids=ids_to_update, metadatas=new_metadatas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c56113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# json file summary update\n",
    "with open('summary.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Update the existing data with the new key-value pair\n",
    "data[new_file_name] = data.pop(old_file_name)\n",
    "\n",
    "with open('summary.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# md and pdf file update\n",
    "# Construct the paths to the folders\n",
    "md_folder = os.path.join(\"data/md\", folder_name)\n",
    "pdf_folder = os.path.join(\"data/pdf\", folder_name)\n",
    "\n",
    "# Construct the old and new file paths\n",
    "old_file_name_md = old_file_name.replace(\".pdf\", \".md\")\n",
    "new_file_name_md = new_file_name.replace(\".pdf\", \".md\")\n",
    "old_md_path = os.path.join(md_folder, old_file_name_md)\n",
    "new_md_path = os.path.join(md_folder, new_file_name_md)\n",
    "\n",
    "# Check if the old MD file exists before renaming\n",
    "if os.path.exists(old_md_path):\n",
    "    # Rename the MD file\n",
    "    os.rename(old_md_path, new_md_path)\n",
    "else:\n",
    "    print(f\"Skipping MD file rename: {old_md_path} does not exist.\")\n",
    "\n",
    "# Construct the old and new file paths\n",
    "old_pdf_path = os.path.join(pdf_folder, old_file_name)\n",
    "new_pdf_path = os.path.join(pdf_folder, new_file_name)\n",
    "\n",
    "# Rename the file\n",
    "os.rename(old_pdf_path, new_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92954856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ValAct_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
